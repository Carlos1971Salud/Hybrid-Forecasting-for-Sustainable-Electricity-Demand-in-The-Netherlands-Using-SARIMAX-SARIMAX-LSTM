{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c337f5e9-a816-40e0-abd9-56a5b2fa2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e114e54c-11f8-4be4-aec6-6923be6b9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = 'processed_data/data_2006_2023.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdefaea-efc9-4e17-9028-44353530249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = pd.read_csv(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb24ee6e-6dd5-43cd-afcd-621e285b39f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loadConsumption</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10215.0000</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2005-12-31 23:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979.0000</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9460.0000</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8833.0000</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-01 02:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8525.0000</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-01-01 03:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157767</th>\n",
       "      <td>12673.4650</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157768</th>\n",
       "      <td>12366.1950</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157769</th>\n",
       "      <td>12143.1775</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157770</th>\n",
       "      <td>11993.1200</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157771</th>\n",
       "      <td>11922.8925</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157772 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loadConsumption        date             datetime  Hour  Year\n",
       "0            10215.0000  2006-01-01  2005-12-31 23:00:00     0  2006\n",
       "1             9979.0000  2006-01-01  2006-01-01 00:00:00     1  2006\n",
       "2             9460.0000  2006-01-01  2006-01-01 01:00:00     2  2006\n",
       "3             8833.0000  2006-01-01  2006-01-01 02:00:00     3  2006\n",
       "4             8525.0000  2006-01-01  2006-01-01 03:00:00     4  2006\n",
       "...                 ...         ...                  ...   ...   ...\n",
       "157767       12673.4650  2023-12-31  2023-12-31 19:00:00    20  2023\n",
       "157768       12366.1950  2023-12-31  2023-12-31 20:00:00    21  2023\n",
       "157769       12143.1775  2023-12-31  2023-12-31 21:00:00    22  2023\n",
       "157770       11993.1200  2023-12-31  2023-12-31 22:00:00    23  2023\n",
       "157771       11922.8925  2023-12-31  2023-12-31 23:00:00    24  2023\n",
       "\n",
       "[157772 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b89cd9a-8108-4137-b3f9-daddb33bf993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity using Augmented Dickey-Fuller test\n",
    "def adf_test(series):\n",
    "    result = adfuller(series)\n",
    "    print(f\"ADF Statistic: {result[0]}\")\n",
    "    print(f\"p-value: {result[1]}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(\"Data is stationary\")\n",
    "    else:\n",
    "        print(\"Data is NOT stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7faf1a2c-77dc-41c1-812d-4e285bb9908d",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 49.3 MiB for an array with shape (41, 157695) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43madf_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloadConsumption\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36madf_test\u001b[1;34m(series)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madf_test\u001b[39m(series):\n\u001b[1;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43madfuller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADF Statistic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp-value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:324\u001b[0m, in \u001b[0;36madfuller\u001b[1;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# 1 for level\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# search for lag length with smallest information criteria\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Note: use the same number of observations to have comparable IC\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# aic and bic: smaller is better\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m regresults:\n\u001b[1;32m--> 324\u001b[0m     icbest, bestlag \u001b[38;5;241m=\u001b[39m \u001b[43m_autolag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mOLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdshort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullRHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautolag\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     icbest, bestlag, alres \u001b[38;5;241m=\u001b[39m _autolag(\n\u001b[0;32m    329\u001b[0m         OLS,\n\u001b[0;32m    330\u001b[0m         xdshort,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m         regresults\u001b[38;5;241m=\u001b[39mregresults,\n\u001b[0;32m    336\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:131\u001b[0m, in \u001b[0;36m_autolag\u001b[1;34m(mod, endog, exog, startlag, maxlag, method, modargs, fitargs, regresults)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(startlag, startlag \u001b[38;5;241m+\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    130\u001b[0m     mod_instance \u001b[38;5;241m=\u001b[39m mod(endog, exog[:, :lag], \u001b[38;5;241m*\u001b[39mmodargs)\n\u001b[1;32m--> 131\u001b[0m     results[lag] \u001b[38;5;241m=\u001b[39m \u001b[43mmod_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    134\u001b[0m     icbest, bestlag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((v\u001b[38;5;241m.\u001b[39maic, k) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:335\u001b[0m, in \u001b[0;36mRegressionModel.fit\u001b[1;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpinv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    332\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_cov_params\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, singular_values \u001b[38;5;241m=\u001b[39m \u001b[43mpinv_extended\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_cov_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\n\u001b[0;32m    337\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog))\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;66;03m# Cache these singular values for use later.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tools\\tools.py:274\u001b[0m, in \u001b[0;36mpinv_extended\u001b[1;34m(x, rcond)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         s[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m--> 274\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res, s_orig\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 49.3 MiB for an array with shape (41, 157695) and data type float64"
     ]
    }
   ],
   "source": [
    "adf_test(load_data[\"loadConsumption\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d4631-a5ac-47c7-a38d-d7943dd1a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (ensure the date column is in datetime format)\n",
    "df = load_data.copy()  \n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07d210-9b6d-4f6b-89de-375aed5bb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate hourly data to daily\n",
    "df_daily = df.groupby(\"date\")[\"loadConsumption\"].sum().reset_index()\n",
    "\n",
    "adf_test(df_daily[\"loadConsumption\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797a83a-bacc-42bd-97a9-291092c943ae",
   "metadata": {},
   "source": [
    "### ARIMA \n",
    "On daily load consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f37cbc-9b2e-41de-8087-bd571d5c8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train-test sets (e.g., last 365 days for testing)\n",
    "train_size = len(df_daily) - 365\n",
    "train, test = df_daily[:train_size], df_daily[train_size:]\n",
    "\n",
    "# Use Auto-ARIMA to find the best (p, d, q) parameters\n",
    "auto_model = auto_arima(train[\"loadConsumption\"], seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "print(f\"Optimal ARIMA parameters: {auto_model.order}\")\n",
    "\n",
    "# Train ARIMA model using the best parameters\n",
    "p, d, q = auto_model.order\n",
    "model = ARIMA(train[\"loadConsumption\"], order=(p, d, q))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make predictions\n",
    "forecast = model_fit.forecast(steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391be80-55c4-4791-871b-5e9985cf3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(test[\"loadConsumption\"], forecast)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape = np.mean(np.abs((test[\"loadConsumption\"] - forecast) / test[\"loadConsumption\"])) * 100\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(test[\"loadConsumption\"], forecast)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(np.mean((forecast - test[\"loadConsumption\"])**2))\n",
    "\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"R^2 Score: {r2:.4f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc1336-97af-4c9d-8e4b-6be6dc7b9643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train[\"date\"], train[\"loadConsumption\"], label=\"Train Data\")\n",
    "plt.plot(test[\"date\"], test[\"loadConsumption\"], label=\"Actual Test Data\", color=\"blue\")\n",
    "plt.plot(test[\"date\"], forecast, label=\"ARIMA Forecast\", color=\"red\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Electricity Load\")\n",
    "plt.title(\"ARIMA Forecast vs Actual Load\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58fd58-c776-422a-b336-0d364f3b5fec",
   "metadata": {},
   "source": [
    "The model is not capturing any pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0edf96-b84d-4e82-a5aa-d3b2a291fcce",
   "metadata": {},
   "source": [
    "### weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27a573-0cab-455e-a7af-74e195b9ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_path = 'processed_data/weather.csv' \n",
    "weather_data = pd.read_csv(weather_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89190e-e7a4-46f9-bd4a-0adb951e7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa7157-6722-452e-a3e3-20b9ed587b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data[\"Date\"] = pd.to_datetime(weather_data[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f9cf1-6aed-451b-b66c-5b67154460af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge temperature data\n",
    "df_merged = pd.merge(df_daily, weather_data, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "df_merged.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bdad3-3386-4ed8-848b-5d46134b8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"is_weekend\"] = df_merged[\"date\"].dt.weekday.apply(lambda x: 1 if x >= 5 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c09a91-201b-4c39-be12-455b709c6ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "# Define holidays for the Netherlands\n",
    "nl_holidays = holidays.NL(years=df_merged[\"date\"].dt.year.unique())\n",
    "\n",
    "# Create a binary column for holidays (1 = holiday, 0 = non-holiday)\n",
    "df_merged[\"is_holiday\"] = df_merged[\"date\"].apply(lambda x: 1 if x in nl_holidays else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d200ac-e665-467e-91ea-da8fc4bd90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904dc1db-740f-4097-bc15-b9eb759d8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.to_csv('df_merged.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68402509-4875-46cc-81aa-5f6b93016df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Drop redundant columns\n",
    "df_cleaned = df_merged.drop(columns=[ \"WeekKey\",\n",
    "                                     \"day_of_week\", \"HDMaxPrecipitation\", \n",
    "                                     \"HDMaxMeanWindspeed\", \"HDMinMeanWindspeed\"])\n",
    "\n",
    "# Convert date column to datetime format\n",
    "df_cleaned[\"date\"] = pd.to_datetime(df_cleaned[\"date\"])\n",
    "\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = numeric_cols.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Electricity Load and Explanatory Variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56afee04-89a3-437b-80b2-2a07aeae9d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1223e2d-708f-459f-9801-67a8df4a8fdd",
   "metadata": {},
   "source": [
    "## SARIMAX (weather data, rolling averags, holiday feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23385680-0c0b-44c0-8f14-4c2e04efe99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime format\n",
    "df_merged[\"date\"] = pd.to_datetime(df_merged[\"date\"])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"WeekKey\",\"Year\", \"Month\",'day_of_week',\n",
    "    \"MaxHourlyPrecipitation\", \"HourlyMaxTemperature\", \"HDMaxTemperature\",  \n",
    "    \"HDMaxMeanWindspeed\", \"HDMinMeanWindspeed\", \"MinHourlyMeanWindspeed\"  \n",
    "]\n",
    "\n",
    "df_sarimax = df_merged.drop(columns=columns_to_drop)\n",
    "\n",
    "# Convert categorical columns to numeric\n",
    "df_sarimax.set_index(\"date\", inplace=True)\n",
    "\n",
    "df_sarimax[\"day_of_week\"] = df_sarimax.index.weekday\n",
    "df_sarimax[\"is_weekend\"] = df_sarimax[\"is_weekend\"].astype(int)\n",
    "df_sarimax[\"is_holiday\"] = df_sarimax[\"is_holiday\"].astype(int)\n",
    "df_sarimax[\"rolling_7d\"] = df_sarimax[\"loadConsumption\"].rolling(7).mean()\n",
    "df_sarimax[\"rolling_30d\"] = df_sarimax[\"loadConsumption\"].rolling(30).mean()\n",
    "df_sarimax = df_sarimax.fillna(method='bfill')  # Fill missing values\n",
    "\n",
    "\n",
    "# Display structure after cleaning\n",
    "df_sarimax.info()\n",
    "df_sarimax.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea432ed-4ef0-4480-9d69-3315f67b93a2",
   "metadata": {},
   "source": [
    " auto_arima helps in selecting the optimal ARIMA model by searching through different combinations of parameters and choosing the best one based on a metric like AIC (Akaike Information Criterion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71617a6-ef65-4c4d-8fd4-3d20e4d0e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "# Run Auto-ARIMA to find optimal parameters\n",
    "auto_model = auto_arima(df_sarimax[\"loadConsumption\"], seasonal=True, m=7, \n",
    "                        exogenous=df_sarimax[[\"day_of_week\", \"rolling_7d\", \"rolling_30d\", \"is_weekend\", \"is_holiday\"]], \n",
    "                        stepwise=True, trace=True)\n",
    "\n",
    "auto_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32843c28-9dc1-4579-8892-20d53c1ccba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e52ecd-2047-46a5-84af-d098abab4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_size = int(len(df_sarimax) * 0.8)\n",
    "train, test = df_sarimax.iloc[:train_size], df_sarimax.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40cee52-a79f-4448-bcb7-b4d685efce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define endogenous (target) and exogenous (features)\n",
    "endog_train = train[\"loadConsumption\"]\n",
    "exog_train = train[[\"day_of_week\", \"rolling_7d\", \"rolling_30d\", \"is_weekend\", \"is_holiday\"]]\n",
    "\n",
    "endog_test = test[\"loadConsumption\"]\n",
    "exog_test = test[[\"day_of_week\", \"rolling_7d\", \"rolling_30d\", \"is_weekend\", \"is_holiday\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ebeb2-2a9b-48fc-b119-584ca2044053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Auto-ARIMA parameters if available\n",
    "best_p, best_d, best_q = auto_model.order  \n",
    "best_P, best_D, best_Q, best_s = auto_model.seasonal_order  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13aa16c-ce81-483c-9241-9cdeddc336f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SARIMAX model\n",
    "sarimax_model = SARIMAX(endog_train, exog=exog_train, \n",
    "                        order=(best_p, best_d, best_q), \n",
    "                        seasonal_order=(best_P, best_D, best_Q, best_s),  \n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "\n",
    "sarimax_fit = sarimax_model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = sarimax_fit.forecast(steps=len(test), exog=exog_test)\n",
    "\n",
    "# Prevent negative values\n",
    "forecast = np.maximum(forecast, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90690cb3-1223-4f61-a47f-82d219ed92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation _ no weather data\n",
    "\n",
    "# RMSE\n",
    "rmse_sarimax = np.sqrt(((forecast - endog_test) ** 2).mean())\n",
    "\n",
    "# R^2 Score\n",
    "r2_sarimax = r2_score(endog_test, forecast)\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "mape_sarimax = np.mean(np.abs((endog_test - forecast) / endog_test)) * 100\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae_sarimax = mean_absolute_error(endog_test, forecast)\n",
    "\n",
    "print(f\" RMSE: {rmse_sarimax}\")\n",
    "print(f\" R2: {r2_sarimax}\")\n",
    "print(f\" MAPE: {mape_sarimax}\")\n",
    "print(f\" MAE: {mae_sarimax}\")\n",
    "\n",
    "# Save metrics to a DataFrame\n",
    "metrics_sarimax_df = pd.DataFrame({\n",
    "    \"Metric\": [\"RMSE\", \"R^2 Score\", \"MAPE\", \"MAE\"],\n",
    "    \"Value\": [rmse_sarimax, r2_sarimax, mape_sarimax, mae_sarimax]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6277bc-4d64-4056-98ab-923cecf680a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index, train[\"loadConsumption\"], label=\"Train Data\")\n",
    "plt.plot(test.index, test[\"loadConsumption\"], label=\"Actual Test Data\", color=\"blue\")\n",
    "plt.plot(test.index, forecast, label=\"SARIMAX Forecast\", color=\"red\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Electricity Load\")\n",
    "plt.title(\"Improved SARIMAX Forecast vs Actual Load\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a24f10-35bd-49db-8f72-fd33b8974b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a CSV file\n",
    "file_path_sarimax = \"metrics/sarimax_metrics.csv\"\n",
    "metrics_sarimax_df.to_csv(file_path_sarimax, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa4862-fdfd-42ae-a425-0ad2ad0fe2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to numeric\n",
    "df_merged.set_index(\"date\", inplace=True)\n",
    "\n",
    "df_merged[\"day_of_week\"] = df_merged.index.weekday\n",
    "df_merged[\"is_weekend\"] = df_merged[\"is_weekend\"].astype(int)\n",
    "df_merged[\"is_holiday\"] = df_merged[\"is_holiday\"].astype(int)\n",
    "df_merged[\"rolling_7d\"] = df_merged[\"loadConsumption\"].rolling(7).mean()\n",
    "df_merged[\"rolling_30d\"] = df_merged[\"loadConsumption\"].rolling(30).mean()\n",
    "df_sarimax = df_sarimax.fillna(method='bfill')  # Fill missing values\n",
    "\n",
    "\n",
    "auto_model_2 = auto_arima(df_merged[\"loadConsumption\"], seasonal=True, m=7, \n",
    "                        exogenous=df_merged[[\"DailyPrecipitation\", \"DailyMeanTemperature\",\n",
    "                                             \"HourlyMinTemperature\", \"day_of_week\",\n",
    "                                             \"rolling_7d\", \"rolling_30d\"]],\n",
    "                        stepwise=True, trace=True)\n",
    "#print(auto_model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee5a8d-9a01-4c0b-bcb4-7bacdf29f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Define endogenous (target) and exogenous (features)\n",
    "endog_train = train[\"loadConsumption\"]\n",
    "exog_train = train[[\"DailyPrecipitation\", \"DailyMeanTemperature\", \"HourlyMinTemperature\", \n",
    "                    \"day_of_week\", \"rolling_7d\", \"rolling_30d\"]]\n",
    "\n",
    "endog_test = test[\"loadConsumption\"]\n",
    "exog_test = test[[\"DailyPrecipitation\", \"DailyMeanTemperature\", \"HourlyMinTemperature\", \n",
    "                \"day_of_week\", \"rolling_7d\", \"rolling_30d\"]]\n",
    "\n",
    "# Use Auto-ARIMA parameters if available\n",
    "best_p, best_d, best_q = auto_model.order  \n",
    "best_P, best_D, best_Q, best_s = auto_model.seasonal_order  \n",
    "\n",
    "# Train SARIMAX model\n",
    "sarimax_model = SARIMAX(endog_train, exog=exog_train, \n",
    "                        order=(best_p, best_d, best_q), \n",
    "                        seasonal_order=(best_P, best_D, best_Q, best_s),  \n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "\n",
    "sarimax_fit = sarimax_model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = sarimax_fit.forecast(steps=len(test), exog=exog_test)\n",
    "\n",
    "# Prevent negative values\n",
    "forecast = np.maximum(forecast, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5017f6-2f98-4f85-9c3d-bb27933c5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "rmse_sarimax2 = np.sqrt(((forecast - endog_test) ** 2).mean())\n",
    "r2_sarimax2 = r2_score(endog_test, forecast)\n",
    "mape_sarimax2 = np.mean(np.abs((endog_test - forecast) / endog_test)) * 100\n",
    "mae_sarimax2 = mean_absolute_error(endog_test, forecast)\n",
    "\n",
    "print(f\"RMSE: {rmse_sarimax2}\")\n",
    "print(f\"R^2 Score: {r2_sarimax2:.4f}\")\n",
    "print(f\"MAPE: {mape_sarimax2:.2f}%\")\n",
    "print(f\"MAE: {mae_sarimax2:.4f}\")\n",
    "\n",
    "# Save metrics to a DataFrame\n",
    "metrics_sarimax_df = pd.DataFrame({\n",
    "    \"Metric\": [\"RMSE\", \"R^2 Score\", \"MAPE\", \"MAE\"],\n",
    "    \"Value\": [rmse_sarimax2, r2_sarimax2, mape_sarimax2, mae_sarimax2]\n",
    "})\n",
    "\n",
    "# Save to a CSV file\n",
    "file_path_sarimax = \"metrics/sarimax_metrics(+weatherDate).csv\"\n",
    "metrics_sarimax_df.to_csv(file_path_sarimax, index=False)\n",
    "\n",
    "print(f\"Metrics saved to: {file_path_sarimax}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d122913-a373-469c-8377-789fdf615506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index, train[\"loadConsumption\"], label=\"Train Data\")\n",
    "plt.plot(test.index, test[\"loadConsumption\"], label=\"Actual Test Data\", color=\"blue\")\n",
    "plt.plot(test.index, forecast, label=\"SARIMAX Forecast\", color=\"red\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Electricity Load\")\n",
    "plt.title(\"Improved SARIMAX Forecast vs Actual Load\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8fd64b-1e2e-45a5-bcf4-5802289315bb",
   "metadata": {},
   "source": [
    "#### 360 days of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d690feb-d4e1-41dd-b622-27cf47c5d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax_fit = sarimax_model.fit()\n",
    "\n",
    "# Forecast for x days\n",
    "forecast_horizon = 365  # Change days\n",
    "forecast = sarimax_fit.forecast(steps=forecast_horizon, exog=exog_test[:forecast_horizon])\n",
    "\n",
    "# Prevent negative values\n",
    "forecast = np.maximum(forecast, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad2097-5567-4b04-9d27-dd0d24f162e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index, train[\"loadConsumption\"], label=\"Train Data\")\n",
    "plt.plot(test.index[:forecast_horizon], test[\"loadConsumption\"].iloc[:forecast_horizon], label=\"Actual Test Data\", color=\"blue\")\n",
    "plt.plot(test.index[:forecast_horizon], forecast, label=\"SARIMAX Forecast\", color=\"red\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Electricity Load\")\n",
    "plt.title(\"Improved SARIMAX Forecast vs Actual Load ({} Days)\".format(forecast_horizon))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c9e86-b0ac-4bf4-9254-291c65f65503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "rmse = np.sqrt(((forecast - endog_test.iloc[:forecast_horizon]) ** 2).mean())\n",
    "r2_sarimax = r2_score(endog_test.iloc[:forecast_horizon], forecast)\n",
    "mape_sarimax = np.mean(np.abs((endog_test.iloc[:forecast_horizon] - forecast) / endog_test.iloc[:forecast_horizon])) * 100\n",
    "mae_sarimax = mean_absolute_error(endog_test.iloc[:forecast_horizon], forecast)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R^2 Score: {r2_sarimax:.4f}\")\n",
    "print(f\"MAPE: {mape_sarimax:.2f}%\")\n",
    "print(f\"MAE: {mae_sarimax:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae84b8-fd97-4224-8185-fd74c9eade67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to a DataFrame\n",
    "metrics_sarimax_df = pd.DataFrame({\n",
    "    \"Metric\": [\"RMSE\", \"R^2 Score\", \"MAPE\", \"MAE\"],\n",
    "    \"Value\": [rmse, r2_sarimax, mape_sarimax, mae_sarimax]\n",
    "})\n",
    "\n",
    "# Save to a CSV file\n",
    "file_path_sarimax = \"metrics/sarimax_metrics(+weather,365).csv\"\n",
    "metrics_sarimax_df.to_csv(file_path_sarimax, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28a231-ef12-49fd-8edb-4f92431431e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
