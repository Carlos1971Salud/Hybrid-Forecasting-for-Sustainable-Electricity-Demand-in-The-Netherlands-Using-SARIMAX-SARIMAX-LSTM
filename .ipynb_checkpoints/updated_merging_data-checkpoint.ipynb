{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c21151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "file_paths = {\n",
    "    \"data_2006_2023\": \"processed_data/data_2006_2023.csv\",\n",
    "    \"elecBalance\": \"processed_data/elecBalance.csv\",\n",
    "    \"energyPrice\": \"processed_data/energyPrice.csv\",\n",
    "    \"GDP\": \"processed_data/GDP.csv\",\n",
    "    \"nao\": \"processed_data/nao.csv\",\n",
    "    \"populationNL\": \"processed_data/populationNL.csv\",\n",
    "    \"renewableEnergy\": \"processed_data/renwableEnergy.csv\",\n",
    "    \"weather\": \"processed_data/weather.csv\",\n",
    "    \"yearlyFinalConsPerSource\": \"processed_data/yearlyfinalConsPerSource.csv\",\n",
    "}\n",
    "\n",
    "dataframes = {name: pd.read_csv(path) for name, path in file_paths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f7bc3b-5a9d-42eb-b9b2-43096e512066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Year' column to `yearlyFinalConsPerSource`\n",
    "dataframes['yearlyFinalConsPerSource']['Year'] = range(2006, 2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4823b705-8818-40fa-b254-d1fb665cf08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter `energyPrice` to keep only rows with `PriceComponents` equal to \"TotalPrice\"\n",
    "if \"PriceComponents\" in dataframes[\"energyPrice\"].columns:\n",
    "    dataframes[\"energyPrice\"] = dataframes[\"energyPrice\"][\n",
    "        dataframes[\"energyPrice\"][\"PriceComponents\"] == \"TotalPrice\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1796cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add or fix the `Year` column in all datasets\n",
    "for name, df in dataframes.items():\n",
    "    if \"Year\" not in df.columns:\n",
    "        if \"Periods\" in df.columns:\n",
    "            # Extract year from 'Periods'\n",
    "            df[\"Year\"] = pd.to_numeric(df[\"Periods\"].str.extract(r\"(\\d{4})\")[0], errors=\"coerce\")\n",
    "        elif \"datetime\" in df.columns:\n",
    "            # Extract year from 'datetime'\n",
    "            df[\"Year\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\").dt.year\n",
    "        elif name == \"yearlyFinalConsPerSource\":\n",
    "            # Add range of years for yearly consumption data\n",
    "            df[\"Year\"] = range(2006, 2023)\n",
    "        else:\n",
    "            print(f\"Cannot derive 'Year' column for dataset: {name}\")\n",
    "    else:\n",
    "        # Ensure `Year` column is numeric\n",
    "        df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5810176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2009\n",
    "end_year = 2022\n",
    "\n",
    "# Filter datasets based on the Year or Date column\n",
    "for name, df in dataframes.items():\n",
    "    if \"Year\" in df.columns:\n",
    "        dataframes[name] = df[(df[\"Year\"] >= start_year) & (df[\"Year\"] <= end_year)]\n",
    "    elif \"Date\" in df.columns:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "        dataframes[name] = df[(df[\"Date\"].dt.year >= start_year) & (df[\"Date\"].dt.year <= end_year)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75949287-1a86-4375-988c-72d176b3a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate hourly loadConsumption data to daily\n",
    "if \"data_2006_2023\" in dataframes:\n",
    "    hourly_data = dataframes[\"data_2006_2023\"]\n",
    "    # Ensure `datetime` is in datetime format\n",
    "    hourly_data[\"datetime\"] = pd.to_datetime(hourly_data[\"datetime\"], errors=\"coerce\")\n",
    "    # Aggregate by date (sum daily consumption)\n",
    "    daily_load = hourly_data.groupby(hourly_data[\"datetime\"].dt.date)[\"loadConsumption\"].sum().reset_index()\n",
    "    daily_load.rename(columns={\"datetime\": \"Date\", \"loadConsumption\": \"daily_load\"}, inplace=True)\n",
    "    daily_load[\"Date\"] = pd.to_datetime(daily_load[\"Date\"])\n",
    "    dataframes[\"data_2006_2023_daily\"] = daily_load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037db1ba-e0c0-45da-ad3c-907793d38a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add `Year` column to datasets where missing\n",
    "for name, df in dataframes.items():\n",
    "    if \"Year\" not in df.columns:\n",
    "        if \"Date\" in df.columns:\n",
    "            df[\"Year\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\").dt.year\n",
    "        elif \"Periods\" in df.columns:\n",
    "            df[\"Year\"] = df[\"Periods\"].str.extract(r\"(\\d{4})\").astype(int)\n",
    "        else:\n",
    "            print(f\"Cannot derive `Year` column for dataset: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93ed88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_to_daily(df, date_col=\"Year\", value_cols=None):\n",
    "    \"\"\"\n",
    "    Upsample data to daily granularity using interpolation or forward-fill.\n",
    "    :param df: Input DataFrame\n",
    "    :param date_col: Column with yearly or monthly values (Year or Date)\n",
    "    :param value_cols: Columns to interpolate (default: numeric columns)\n",
    "    :return: DataFrame with daily granularity\n",
    "    \"\"\"\n",
    "    # Ensure the column exists\n",
    "    if date_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{date_col}' not found in DataFrame. Available columns: {df.columns}\")\n",
    "    \n",
    "    # Convert date_col to datetime if it's not already\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    if df[date_col].isnull().all():\n",
    "        raise ValueError(f\"Column '{date_col}' could not be converted to datetime.\")\n",
    "\n",
    "    # Create daily date range and upsample\n",
    "    daily_df = pd.DataFrame({'Date': pd.date_range(start=df[date_col].min(), end=df[date_col].max(), freq=\"D\")})\n",
    "    daily_df = daily_df.merge(df, left_on=\"Date\", right_on=date_col, how=\"left\").drop(columns=[date_col])\n",
    "\n",
    "    # Interpolate specified value columns\n",
    "    if value_cols:\n",
    "        daily_df[value_cols] = daily_df[value_cols].interpolate(method=\"linear\").fillna(method=\"bfill\")\n",
    "\n",
    "    return daily_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69de53b6-79f0-4e65-a51a-0dbc9cd0aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and fix `Year` column across datasets\n",
    "for name, df in dataframes.items():\n",
    "    if \"Year\" not in df.columns:\n",
    "        print(f\"Dataset '{name}' is missing the 'Year' column.\")\n",
    "    else:\n",
    "        try:\n",
    "            df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "            if df[\"Year\"].isna().any():\n",
    "                print(f\"Dataset '{name}' has invalid 'Year' values after conversion.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing 'Year' in dataset '{name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1220dd88-857d-4516-918a-a1e6f971af57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting dataset 'populationNL'...\n"
     ]
    }
   ],
   "source": [
    "# Check and convert non-numeric columns for datasets where needed\n",
    "for name, df in dataframes.items():\n",
    "    if name == \"populationNL\":\n",
    "        print(f\"Inspecting dataset '{name}'...\")\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not convert column '{col}' in dataset '{name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938471c3-f2b5-4728-971c-1e7073a678ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample_to_daily function\n",
    "def upsample_to_daily(df, date_col=\"Year\", value_cols=None):\n",
    "    \"\"\"\n",
    "    Upsample data to daily granularity using interpolation and forward/backward filling.\n",
    "    \"\"\"\n",
    "    if date_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{date_col}' not found in DataFrame. Available columns: {df.columns}\")\n",
    "\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    if df[date_col].isnull().all():\n",
    "        raise ValueError(f\"Column '{date_col}' could not be converted to datetime.\")\n",
    "\n",
    "    daily_df = pd.DataFrame({\"Date\": pd.date_range(start=df[date_col].min(), end=df[date_col].max(), freq=\"D\")})\n",
    "    daily_df = daily_df.merge(df, left_on=\"Date\", right_on=date_col, how=\"left\").drop(columns=[date_col])\n",
    "\n",
    "    if value_cols:\n",
    "        daily_df[value_cols] = daily_df[value_cols].interpolate(method=\"linear\").bfill().ffill()\n",
    "\n",
    "    return daily_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a639c91-91dd-4506-843e-b0e3566bae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset 'data_2006_2023': \"['Year'] not in index\"\n",
      "Error processing dataset 'elecBalance': \"['Year'] not in index\"\n",
      "Error processing dataset 'energyPrice': \"['Year'] not in index\"\n",
      "Error processing dataset 'GDP': \"['Year'] not in index\"\n",
      "Error processing dataset 'nao': \"['Year'] not in index\"\n",
      "Error processing dataset 'populationNL': \"None of [Index(['Year'], dtype='object')] are in the [columns]\"\n",
      "Error processing dataset 'renewableEnergy': \"['Year'] not in index\"\n",
      "Error processing dataset 'weather': \"['Year'] not in index\"\n",
      "Error processing dataset 'yearlyFinalConsPerSource': \"['Year'] not in index\"\n",
      "Error processing dataset 'data_2006_2023_daily': \"['Year'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "# Skip datasets without numeric columns during upsampling\n",
    "upsampled_dataframes = {}\n",
    "for name, df in dataframes.items():\n",
    "    numeric_columns = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "    if not numeric_columns:\n",
    "        print(f\"Skipping dataset '{name}' - No numeric columns for upsampling.\")\n",
    "        continue\n",
    "    try:\n",
    "        upsampled_dataframes[name] = upsample_to_daily(df, date_col=\"Year\", value_cols=numeric_columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing dataset '{name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f87a5-5b76-45b3-96ef-4c725c2fa022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix or add the 'Year' column for all datasets\n",
    "for name, df in dataframes.items():\n",
    "    if \"Year\" not in df.columns:\n",
    "        if \"Periods\" in df.columns:\n",
    "            # Extract year from 'Periods'\n",
    "            df[\"Year\"] = pd.to_numeric(df[\"Periods\"].str.extract(r\"(\\d{4})\")[0], errors=\"coerce\")\n",
    "        elif \"datetime\" in df.columns:\n",
    "            # Extract year from 'datetime'\n",
    "            df[\"Year\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\").dt.year\n",
    "        elif name == \"yearlyFinalConsPerSource\":\n",
    "            # Add range of years for yearly consumption data\n",
    "            df[\"Year\"] = range(2006, 2023)\n",
    "        else:\n",
    "            print(f\"Cannot derive 'Year' column for dataset: {name}\")\n",
    "    else:\n",
    "        # Ensure 'Year' column is numeric\n",
    "        df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
